# Logistic Sigmoid

在使用ReLU之前经常使用的激活函数。这个和`tanh` 函数相关，因为$$\tanh(z)=2\sigma(2z)$$

## 特性：

* ✅   可以表示0-1区域内的概率
* ❌   绝大多数区域内饱和
* ❌   通常没有$$tanh$$表现好，因为$$tanh$$在零附近接近单位函数。训练已$$\tanh$$激活的函数类似训练一个纯线性网络，更加容易

## 使用场景：

* 循环网络
* 许多概率模型
* 自编码器有额外要求不能使用分段线性激活函数

