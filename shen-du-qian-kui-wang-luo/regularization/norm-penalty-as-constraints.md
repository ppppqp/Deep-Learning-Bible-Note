# Norm Penalty as Constraints

## 带约束的优化问题

将范数正则化看作是带约束的优化问题。对于一个带约束的优化问题，我们可以构造一个广义的Lagrange 函数来最小化带约束的函数，即在原始目标函数上添加一系列惩罚项。每个惩罚项被称为一个Karush-Kuhn-Tucker乘子系数以及一个表示约束是否满足的函数之间的乘积。

> 也就是把带约束的优化问题转换为一类特殊的无约束优化问题

具体来说，我们的优化问题是$$\widetilde J(\theta; X,y) = J(\theta; X,y)+\alpha \Omega(\theta)$$。如果我们想让那个$$\Omega(\theta)$$小于某个常数k，那么可以构造Lagrange函数$$\mathcal{L}(\theta, \alpha; X,y) = J(\theta; X,y) + \alpha(\Omega(\theta) - k)$$。那么约束问题的解t就是$$\theta = \underset{\theta}{argmin} \underset{\alpha, \alpha \geq 0}{\max} \mathcal{L}(\theta, \alpha)$$。如果我们固定$$\alpha$$，那么就和正则化训练完全一样。$$\alpha$$表明了约束的条件，也就是对应的k值。

> 需要学习一下KKT优化，先看看445会不会讲，pending

## 显式约束（重投影）

有时候，我们希望使用显示的限制，而不是惩罚。比如，先计算$$J(\theta)$$的gradient再将$$\theta$$投影到满足$$\Omega(\theta) < k $$的最近点。如果我们知道什么样的k是合适的，这会非常有用。

> 即强行限制$$\theta$$的大小，前提是知道这个阈值。

另一个使用显式约束的原因是，惩罚可能是的目标函数非凸而使得算法陷入局部极小。通常表现为带有几个“死亡单元“的神经网络。这些单元不会对网络学习到的函数没有太大影响，因为进入和离开的权重都很小。而显式约束不会鼓励权重接近原点，所以效果更好。

> 简单来说就是如果$$\alpha$$太大，会导致$$\theta$$非常小，训练损失函数效果偏重于拟合接近零的$$\theta$$，导致欠拟合

最后，显示约束和重投影对优化过程增加了一定的稳定性。学习率较高时，容易诱导较大梯度，使得权重获得重大更新。如果这些更新持续增加权重大小，$$\theta$$会迅速增大，直到溢出。显示约束可以防止这种反馈环的产生。建议结合使用约束和高学习速率，来更快地探索参数空间。

> 在保持稳定性前提下加快学习的方法论



