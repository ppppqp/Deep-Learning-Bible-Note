# Table of contents

* [ReadMe](README.md)

## deep feed forward network <a id="shen-du-qian-kui-wang-luo"></a>

* [intro](shen-du-qian-kui-wang-luo/yin-yan.md)
* [Learning XOR](shen-du-qian-kui-wang-luo/learning-xor.md)
* [Gradient Learning](shen-du-qian-kui-wang-luo/gradient-learning/README.md)
  * [Loss Function](shen-du-qian-kui-wang-luo/gradient-learning/loss-function.md)
  * [Output Unit](shen-du-qian-kui-wang-luo/gradient-learning/output-unit/README.md)
    * [Linear Unit](shen-du-qian-kui-wang-luo/gradient-learning/output-unit/linear-unit.md)
    * [Sigmoid Unit](shen-du-qian-kui-wang-luo/gradient-learning/output-unit/sigmoid-unit.md)
    * [Softmax Unit](shen-du-qian-kui-wang-luo/gradient-learning/output-unit/softmax-unit.md)
  * [Hidden Unit](shen-du-qian-kui-wang-luo/gradient-learning/hidden-unit/README.md)
    * [ReLU and extensions](shen-du-qian-kui-wang-luo/gradient-learning/hidden-unit/relu-and-extensions.md)
    * [Logistic Sigmoid](shen-du-qian-kui-wang-luo/gradient-learning/hidden-unit/logistic-sigmoid.md)
    * [Others](shen-du-qian-kui-wang-luo/gradient-learning/hidden-unit/others.md)
  * [Architecture Design](shen-du-qian-kui-wang-luo/gradient-learning/architecture-design/README.md)
    * [Universal Approximation Theorem](shen-du-qian-kui-wang-luo/gradient-learning/architecture-design/universal-approximation-theorem.md)
* [Regularization](shen-du-qian-kui-wang-luo/regularization/README.md)
  * [Parameter Norm Penalty](shen-du-qian-kui-wang-luo/regularization/parameter-norm-penalty/README.md)
    * [L2 Regularization](shen-du-qian-kui-wang-luo/regularization/parameter-norm-penalty/l2-regularization.md)
    * [L1 Regularization](shen-du-qian-kui-wang-luo/regularization/parameter-norm-penalty/l1-regularization.md)
  * [Norm Penalty as Constraints](shen-du-qian-kui-wang-luo/regularization/norm-penalty-as-constraints.md)
  * [Regularization and Underconstrained Problem](shen-du-qian-kui-wang-luo/regularization/regularization-and-underconstrained-problem.md)
  * [Data Augmentation](shen-du-qian-kui-wang-luo/regularization/data-augmentation.md)
  * [Robustness](shen-du-qian-kui-wang-luo/regularization/robustness.md)
  * [Semi-supervised Learning](shen-du-qian-kui-wang-luo/regularization/semi-supervised-learning.md)

