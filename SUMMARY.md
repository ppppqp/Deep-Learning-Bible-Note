# Table of contents

* [ReadMe](README.md)

## deep feed forward network <a id="shen-du-qian-kui-wang-luo"></a>

* [intro](shen-du-qian-kui-wang-luo/yin-yan.md)
* [Learning XOR](shen-du-qian-kui-wang-luo/learning-xor.md)
* [Gradient Learning](shen-du-qian-kui-wang-luo/gradient-learning/README.md)
  * [Loss Function](shen-du-qian-kui-wang-luo/gradient-learning/loss-function.md)
  * [Output Unit](shen-du-qian-kui-wang-luo/gradient-learning/output-unit/README.md)
    * [Linear Unit](shen-du-qian-kui-wang-luo/gradient-learning/output-unit/linear-unit.md)
    * [Sigmoid Unit](shen-du-qian-kui-wang-luo/gradient-learning/output-unit/sigmoid-unit.md)
    * [Softmax Unit](shen-du-qian-kui-wang-luo/gradient-learning/output-unit/softmax-unit.md)
  * [Hidden Unit](shen-du-qian-kui-wang-luo/gradient-learning/hidden-unit/README.md)
    * [ReLU and extensions](shen-du-qian-kui-wang-luo/gradient-learning/hidden-unit/relu-and-extensions.md)
    * [Logistic Sigmoid](shen-du-qian-kui-wang-luo/gradient-learning/hidden-unit/logistic-sigmoid.md)
    * [Others](shen-du-qian-kui-wang-luo/gradient-learning/hidden-unit/others.md)
  * [Architecture Design](shen-du-qian-kui-wang-luo/gradient-learning/architecture-design/README.md)
    * [Universal Approximation Theorem](shen-du-qian-kui-wang-luo/gradient-learning/architecture-design/universal-approximation-theorem.md)

